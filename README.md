# Diabetes
In this project, I explored six different machine learning models 🤖🧠 to predict diabetes risk in individuals using the dataset. The models I tried were:

Logistic Regression 📉
Decision Trees 🌳
Bagging 🛍️
Random Forest 🌲🌳
K-Nearest Neighbors (KNN) 🤝
Support Vector Machine (SVM) 🏋️‍♀️
It was fascinating to witness how these models performed differently based on their unique characteristics. The insights gained through Exploratory Data Analysis (EDA) helped me understand the data better, and Python's versatility made implementing these models a breeze.

Here are some key takeaways from the project:
🎯 Random Forest and Bagging emerged as top performers with high accuracy and balanced precision-recall trade-offs.
📊 Decision Trees provided valuable interpretability, aiding our understanding of feature importance.
🤔 KNN and SVM showed promise but may require further tuning for optimal performance.

This project has been an enriching journey, teaching me the importance of model selection and the impact of various hyperparameters on the results.
